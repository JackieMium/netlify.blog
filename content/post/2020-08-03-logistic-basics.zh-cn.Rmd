---
title: 复习下 Logistic 回归基础
author: Jackie
date: '2020-08-03'
slug: logistic-basics
categories:
  - Stats
tags:
  - 基础
  - R
  - stats
toc: yes
comment: yes
lastmod: '2020-08-03T21:08:33+08:00'
autoCollapseToc: no
---

这一篇算是复习了，日渐觉得对于 Logsitic 回归了解得有点飘。这一篇就是找几个比较基础的东西看一下然后把 Logistic 回归从前到后过一遍。涉及到模型构建、模型拟合优度（Goodness of fit）、区分度（Discrimination）和校准度（Calibration）评价。

<!--more-->

整体参考了 [Manny Gimond 的 一篇博文：Logistic regression](https://mgimond.github.io/Stats-in-R/Logistic.html)。

数据使用的是 **mlbench** 包里的 `PimaIndiansDiabetes2`。这是一个根据患者年龄、BMI、怀孕次数、OGTT 后胰岛素水平和 OGTT（口服糖耐量试验）血糖结果等等变量预测糖尿病（二分类，Neg vs. Pos）的数据，正好可以作为 Logistic 回归的例子。具体介绍可以参看 Kaggle [Pima Indians Diabetes Database: Predict the onset of diabetes based on diagnostic measures](https://www.kaggle.com/uciml/pima-indians-diabetes-database)

用到的包不多，主要就是数据清洗和可视化，**rms** 希望有机会（又挖坑了嘿）可以深入学习一下，这里只是简单用一下。

```{r setup, message=FALSE}
library("dplyr")
library("ggplot2")
library("ggbeeswarm")
library("beeswarm")
library("rms")
library("pscl") # McFadden R2

set.seed(1234)

theme_set(theme_minimal())
```

# 数据

载入数据之后发现数据里有缺失值，这里图方便直接就不要含缺失值的数据了。然后把 BMI 从连续型变量切分成因子类，由于低体重组人数太少（只有一个）直接合并到正常体重组了。

```{r data, echo=TRUE, collapse=TRUE}
data("PimaIndiansDiabetes2", package="mlbench")
head(PimaIndiansDiabetes2)

dim(PimaIndiansDiabetes2)


sapply(PimaIndiansDiabetes2, function(x) sum(is.na(x)))

dbt <- tibble(PimaIndiansDiabetes2) %>%
  na.omit() %>%
  mutate(bmi = factor(case_when(
    # mass < 18.5 ~ "underweight",
    mass < 25 ~ "normal",
    mass >= 25 & mass < 30 ~ "overweight",
    mass >= 30 ~ "obese"),
    levels = c("normal", "overweight", "obese"))
    ) %>%
  select(-mass)
levels(dbt$diabetes) <- c(0, 1)

# rms option
dd <- datadist(dbt)
options(datadist = "dd")
```

先来看看很明显的，糖尿病和非糖尿病两组之间血糖是一样的吗？假装并不知道血糖高说明有糖尿病....


```{r glucose, echo=TRUE}
par(mar = c(4.1, 4.1, 1.1, 2.1))
boxplot(glucose ~ diabetes, data = dbt, 
        col = "white",
        outline = FALSE)
beeswarm(glucose ~ diabetes, data = dbt, 
         pch = 21, col = 2:3, 
         bg = "grey",
         add = TRUE)
p1 <- grDevices::recordPlot()
```

这里插播两个小东西： **ggplot** 版的的 beeswarm 图，由 **ggbeeswarm** 提供；以及`grDevices::recordPlot()` 这个黑魔法。两个图放在一起对比一下（）：

```{r glucose-beeswarm, echo=TRUE,warning=FALSE}
p2 <- ggplot(dbt, aes(x= diabetes, y = glucose)) +
    geom_boxplot(width = 1/2, outlier.shape = NA) +
    geom_beeswarm(alpha = 1/3) +
    labs(x = "Diabetes",
         y = "OGTT Plasma glucose conc.") +
    NULL

cowplot::plot_grid(p1, p2, 
                   # rel_widths = c(1, 2),
                   ncol = 2)
```

不出所料，糖尿病患者血糖水平似乎更高。

再来把坐标轴转换一下，如果血糖水平作为横轴、糖尿病是否作为纵轴会是什么样子？

```{r geom_point, echo=FALSE}
ggplot(dbt, aes(glucose, diabetes)) +
geom_point(alpha = 1/10) +
  labs(y = "Diabetes",
       x = "OGTT Plasma glucose conc") +
  NULL
```

由于 diabetes 只取 0/1，大量散点相互覆盖。

尝试用不同的方法取拟合一条曲线来看变量之间的关系：

```{r stat_smooth, echo=FALSE}
ggplot(dbt, aes(glucose, as.numeric(diabetes) - 1)) +
    geom_point(alpha = 1/10) + 
    stat_smooth(formula = y ~ x, method="glm", aes(color = "blue"),
                method.args = list(family=binomial), 
                fullrange=TRUE, se=FALSE, alpha = 1/5, linetype = 2) + 
    labs(y = "Diabetes probility",
         x = "OGTT Plasma glucose conc.") + 
    stat_smooth(formula = y ~ x, method = "lm", aes(color = "red"), 
                linetype = 1, se = FALSE, alpha = 1/5) + 
    stat_smooth(formula = y ~ x, method = "loess", aes(color = "green"),
                linetype = 5, se = FALSE, alpha = 1/4) +
    xlim(0, 250) +
    scale_color_manual(name = "",
                       values = c("blue" = "blue",
                                  "red" = "red",
                                  "green" = "green"),
                       labels = c("logit", "loess(default)", "lm")) +
    # theme_minimal() +
    theme(legend.position = c(.9, .6)) +
    NULL 
```

能看到确实 logit 拟合还是不错的样子。直接来上 Logistic 回归模型吧：

# 模型 1

```{r model1, collapse=TRUE}
M1 <- glm(diabetes ~ glucose, family = binomial, data = dbt)
M1

summary(M1)

round(exp(cbind(OR = coef(M1), confint(M1))), 2)
```

首先 glucose 显著相关（of course），系数是 0.04 表明是血糖高糖尿病可能性也提高（不一定是因果，只说明正相关）。
模型 AIC 370.9，残差 386.7，Null 模型（只有截距）的残差 498.1。可以看到即使加入一个显著解释变量的时候残差也“明显”降低了（“明显”打了引号是因为这只是直觉上的明显降低，至于是否真的降低要用统计检验来证明。后面模型诊断评价涉及）。

用这个模型来预测糖尿病看看之前的曲线会是什么样子：

```{r pred}
M.df <- data.frame(glucose = seq(0, 300, 1))
M.df$diabetes = predict(M1, newdata = M.df, type = "response")
```

生成新的预测数据之后，再来用这个数据作图：

```{r plotpred, echo=TRUE}
ggplot(M.df, aes(x = glucose, y = diabetes)) +
  geom_line(size = 1.2, aes(color = "blue"), alpha = 1/2) +
  geom_point(data = dbt,
             aes(glucose, as.numeric(diabetes) - 1),
             alpha = 1/10) +
  geom_smooth(data = dbt, formula = y ~ x, 
              method = "glm", method.args = list(family = "binomial"), 
              se = FALSE, 
              size = .5,
             aes(glucose, as.numeric(diabetes) - 1, color = "red")) +
  scale_color_manual(name = "",
                       values = c("blue" = "blue",
                                  "red" = "red"),
                       labels = c("Predicted data", "Real data")) +
  labs(y = "Diabetes probility",
       x = "OGTT Plasma glucose conc.") +
  theme(legend.position = c(.9, .5)) +
  NULL
```

# 模型评价

在线性模型里，一个很重要的评价模型的参数就是 $R^2$，它表示模型可解释的变异占总变异的比例。很显然，这个比例越高越好。

Logistic 回归是一种广义线性模型。如果还用 $R^2$ 来评价模型，就得到所谓“伪” R 方，pseudo $R^2$，也叫 McFadden’s $R^2$ 。可以根据它的定义自己计算，也可以直接用 **pscl** 包的 `pR2()`: 

```{r pseudo-R-square, collapse=TRUE}
-2 * logLik(M1)
M1$deviance

-2 * logLik(update(M1, .~. - glucose))
M1$null.deviance


M1.pseudo.R2 <- (M1$null.deviance - M1$deviance) / M1$null.deviance
M1.pseudo.R2

pR2(M1)["McFadden"]
```

参考 [StackExchange: McFadden's Pseudo-$R^2$  Interpretation](https://stats.stackexchange.com/q/82105)，0.2 - 0.4 之间认为模型表现 OK (excellent performance)。

另外对于模型评价还有其他一些指标，在 **rms** 包 `lrm()` 可以非常方便的得到：

```{r lrm-m1, collapse=TRUE}
M1.lrm <- lrm(diabetes ~ glucose, data = dbt)
M1.lrm

summary(M1.lrm)

M1.lrm$stats[c("R2", "Brier", "C", "Dxy")]
```
这里给出的信息很丰富，捡几个常见的说一下：

- R2 是 the Nagelkerke R^2 index，具体计算公式不列了，取值范围 0~1。是 Discrimination 参数
- [Brier score](https://en.wikipedia.org/wiki/Brier_score) 在文献里也经常看到，计算方法就是预测值和观察值差值的平方和除以观测数。`DescTools::BrierScore()` 也可以计算，或者依据公式其实就是 `mean((M1$y - M1$fitted.values)^2)` 的结果
越小表示模型预测约准确。Discrimination 参数
- C 就是经常见到的 C 统计量，C statistic，Concordance index，和 AUC 是相等的
- Dxy 是 [Somers' *D*](https://en.wikipedia.org/wiki/Somers%27_D)， 具体公式不给了，略复杂。对于 Logistic 回归，Dxy = 2 * (AUC - 0.5)
- Dxy 和 Tau-a 的具体介绍可以看 [Logistic regression, Gamma (Goodman and Kruskal Gamma)](http://shashiasrblog.blogspot.com/2014/01/binary-logistic-regression-on-r.html)，文末把这篇博文的代码附上

比较不同模型之间是否有统计学差异，用卡方检验，卡方值是两模型残差相减，自由度两模型自由度之差。比如前面提到 M1 只是有一个变量 glucose 的时候模型残差已经明显降低，那相比 Null 模型，M1 是不是真的“统计学显著地显著”更好呢？

```{r chi-M1, collapse=TRUE}
(M1Chidf <- M1$df.null - M1$df.residual)
(M1Chi <- M1$null.deviance - M1$deviance)
(M1chisq.prob <- 1 - pchisq(M1Chi, M1Chidf))

# 或者一步计算
with(M1, pchisq(null.deviance - deviance,
                df.null - df.residual,
                lower.tail = FALSE))
```

对照输出参看 M1.lrm 可以看到 Model Likelihood 那里的输出就是这里的计算结果。

现在在 M1 的基础上再添加一个变量 bmi：

```{r m2, collapse=TRUE}
M2 <- glm(diabetes ~ glucose + bmi, dbt, family = binomial)
summary(M2)

round(exp(cbind(OR = coef(M2), confint(M2))), 2)

M2.pseudo.R2 <- (M2$null.deviance - M2$deviance) / M2$null.deviance
M2.pseudo.R2


with(M2, pchisq(null.deviance - deviance,
                df.null - df.residual,
                lower.tail = FALSE))

M2.lrm <- lrm(diabetes ~ glucose + bmi, data = dbt)
M2.lrm

summary(M2.lrm)
```

M2 在 M1 的基础上多个模型参数都有提升，一样的，统计学显著吗？

```{r compare-m1m2, collapse=TRUE}
anova(M1, M2, test = "Chi")


lrtest(M1.lrm, M2.lrm)
```

卡方检验显示 M2 明显优于 M1。

下面涉及到模型的校准（calibration），**rms** 做起来很方便，就直接用 rms 来继续吧：

# 简单看看 **rms**

首先是通过 bootstrap 内部验证（internal-validation）来看模型是否有明显过拟合：

```{r valid, collapse=TRUE}
M1.lrm <- lrm(diabetes ~ glucose, data = dbt, 
              x = TRUE, y = TRUE)
M1.lrm


M1.valid <- validate(M1.lrm, method = "boot", B = 1000)
M1.valid


M2.lrm <- lrm(diabetes ~ glucose + bmi, data = dbt, 
              x = TRUE, y = TRUE)
M2.lrm


M2.valid <- validate(M2.lrm, method = "boot", B = 1000)
M2.valid
```

给出的结果里 Dxy 和 R^2 分别有 training 和 test 的值已经据此计算出的 optimism，然后给出了校正值。这里可以看到其实 M1、M2 的过拟合不明显。

做 Calibration 曲线图：

```{r cliab, collapse=TRUE}
myPlotCalib <- function (x, xlab, ylab, xlim, ylim, 
                         legend = TRUE, subtitles = TRUE, 
                        cols = c("red", "darkgreen", "black"),
                        lty = c(2, 3, 1),
                        cex.subtitles = 0.75, riskdist = TRUE, 
                        scat1d.opts = list(nhistSpike = 200), ...) 
{
    at <- attributes(x)
    if (missing(ylab)) 
        ylab <- if (at$model == "lr") 
            "Actual Probability"
    else paste("Observed", at$yvar.name)
    if (missing(xlab)) {
        if (at$model == "lr") {
            xlab <- paste("Predicted Pr{", at$yvar.name, sep = "")
            if (at$non.slopes == 1) {
                xlab <- if (at$lev.name == "TRUE") 
                    paste(xlab, "}", sep = "")
                else paste(xlab, "=", at$lev.name, "}", sep = "")
            }
            else xlab <- paste(xlab, ">=", at$lev.name, "}", 
                               sep = "")
        }
        else xlab <- paste("Predicted", at$yvar.name)
    }
    p <- x[, "predy"]
    p.app <- x[, "calibrated.orig"]
    p.cal <- x[, "calibrated.corrected"]
    if (missing(xlim) & missing(ylim)) 
        xlim <- ylim <- range(c(p, p.app, p.cal), na.rm = TRUE)
    else {
        if (missing(xlim)) 
            xlim <- range(p)
        if (missing(ylim)) 
            ylim <- range(c(p.app, p.cal, na.rm = TRUE))
    }
    plot(p, p.app, xlim = xlim, ylim = ylim, xlab = xlab, ylab = ylab, 
         type = "n", ...)
    predicted <- at$predicted
    err <- NULL
    if (length(predicted)) {
        s <- !is.na(p + p.cal)
        err <- predicted - approx(p[s], p.cal[s], xout = predicted, 
                                  ties = mean)$y
        cat("\nn=", n <- length(err), "   Mean absolute error=", 
            round(mae <- mean(abs(err), na.rm = TRUE), 3), 
            "   Mean squared error=", 
            round(mean(err^2, na.rm = TRUE), 5), 
            "\n0.9 Quantile of absolute error=", 
            round(quantile(abs(err), 0.9, na.rm = TRUE), 3), 
            "\n\n", sep = "")
        if (subtitles) 
            title(sub = paste("Mean absolute error=", 
                              round(mae, 3), " n=", n, sep = ""), 
                  cex.sub = cex.subtitles, 
                  adj = 1)
        if (riskdist) 
            do.call("scat1d", c(list(x = predicted), scat1d.opts))
    }
    lines(p, p.app, lty = lty[1], col = cols[1], lwd = 2)
    lines(p, p.cal, lty = lty[2], col = cols[2], lwd = 2)
    abline(a = 0, b = 1, lty = lty[3], col = cols[3])
    if (subtitles) 
        title(sub = paste("B =", at$B, "repetitions,", at$method), 
              cex.sub = cex.subtitles, adj = 0)
    if (!(is.logical(legend) && !legend)) {
        if (is.logical(legend)) 
            legend <- list(x = xlim[1] + 0.5 * diff(xlim), y = ylim[1] + 
                               0.32 * diff(ylim))
        legend(legend, c("Apparent", "Bias-corrected", "Ideal"), 
               lwd = 1.75, seg.len = 1, cex = .75,
               lty = lty, bty = "n", col = cols)
    }
    invisible(err)
}

par(mar = c(5.1, 4.1, 2, 0.5),
    mfrow = c(1, 2))
M1.calib <- calibrate(M1.lrm, method = "boot", B = 1000)
M2.calib <- calibrate(M2.lrm, method = "boot", B = 1000)

myPlotCalib(M1.calib, las = 1, main = "M1 Calibration", cex.subtitles = 0.5, 
     xlab = "Predicted probability",
     ylab = "Observed probability")
par(mar = c(5.1, 2.5, 2, 2.1))
myPlotCalib(M2.calib, las = 1,  main = "M2 Calibration", cex.subtitles = 0.5,
            xlab = "Predicted probability"
            )
```

这里由于嫌原来 **rms** 提供的作图函数不能自定义颜色所以自己把提取出来的函数改了一下（参考了 [StackOverflow: Changing the colour of a calibration plot](https://stackoverflow.com/q/57834244)）。

这个图解释一下：

- 上面 X 轴的 rug plot 表示预测值的分布情况，可以看到多数病例 diabetes = 0, 当然可以自己 `table(dbt$diabetes)` 验证一下
- 标记为“Apparent”的这条曲线就是样本内校准情况
- 标记为“Ideal”的是完美模型的情况，因为 x = y 即所有预测值和实际值完全相同
- 标记为“Bias Corrected” 的是通过 bootstrap 抽样校准了过拟合情况的结果，这也是理论上模型用到新数据中做预测时表现的预测情形。这条曲线也是考察模型外推性的依据
- Mean absolute error （MAE）是预测值和实际值平均绝对值差值了, Mean squared error（MSE） 就是均方差了，类比一下方差和标准差很好理解。

从这些结果看 M1.lrm 和 M2.lrm 的模型校准度也还可以，在 0.4 左右有一点点高估和低估。


# 附

在一篇博文里看到的计算 Dxy 和 Tau-a 的实现，没有深究，代码看一下：

```r
# http://shashiasrblog.blogspot.com/2014/01/binary-logistic-regression-on-r.html
# Logistic regression, Gamma (Goodman and Kruskal Gamma),
# Somers' D, Kendall's Tau A

OptimisedConc = function(model)
{
  Data = cbind(model$y, model$fitted.values)
  ones = Data[Data[, 1] == 1, ]
  zeros = Data[Data[, 1] == 0, ]
  conc = matrix(0, dim(zeros)[1], dim(ones)[1])
  disc = matrix(0, dim(zeros)[1], dim(ones)[1])
  ties = matrix(0, dim(zeros)[1], dim(ones)[1])
  for (j in 1:dim(zeros)[1]) {
    for (i in 1:dim(ones)[1]) {
      if (ones[i, 2] > zeros[j, 2]) {
        conc[j, i] = 1
        }
      else if (ones[i, 2] < zeros[j, 2]) {
        disc[j, i] = 1
      }
      else if (ones[i, 2] == zeros[j, 2]) {
        ties[j, i] = 1
      }
    }
  }
  Pairs = dim(zeros)[1] * dim(ones)[1]
  PercentConcordance = (sum(conc) / Pairs) * 100
  PercentDiscordance = (sum(disc) / Pairs) * 100
  PercentTied = (sum(ties) / Pairs) * 100

  PercentConcordance = (sum(conc) / Pairs) * 100
  PercentDiscordance = (sum(disc) / Pairs) * 100
  PercentTied = (sum(ties) / Pairs) * 100
  N <- length(model$y)
  gamma <- (sum(conc) - sum(disc)) / Pairs
  Somers_D <- (sum(conc) - sum(disc)) / (Pairs - sum(ties))
  k_tau_a <- 2 * (sum(conc) - sum(disc)) / (N * (N - 1))
  return(list("Percent Concordance" = PercentConcordance,
      "Percent Discordance" = PercentDiscordance,
      "Percent Tied" = PercentTied,
      "Pairs" = Pairs,
      "Gamma" = gamma,
      "Somers D" = Somers_D,
      "Kendall's Tau A" = k_tau_a))

  # return(list("Percent Concordance" = PercentConcordance,
  # "Percent Discordance"=PercentDiscordance,
  # "Percent Tied" = PercentTied,
  # "Pairs" = Pairs))
}
```

还有一个实现多种拟合优度检验的实现：

```r
#####################################################################
# NAME: Tom Loughin                                                 #
# DATE: 1-10-13                                                     #
# PURPOSE: Functions to compute Hosmer-Lemeshow, Osius-Rojek, and   #
#     Stukel goodness-of-fit tests                                  #
#                                                                   #
# NOTES:                                                            #
#####################################################################
# Single R file that contains all three goodness-of fit tests
# http://www.chrisbilder.com/categorical/Chapter5/AllGOFTests.R

# Adapted from program published by Ken Kleinman as Exmaple 8.8 on the SAS and R blog, sas-and-r.blogspot.ca 
#  Assumes data are aggregated into Explanatory Variable Pattern form.

HLTest = function(obj, g) {
 # first, check to see if we fed in the right kind of object
 stopifnot(family(obj)$family == "binomial" && family(obj)$link == "logit")
 y = obj$model[[1]]
 trials = rep(1, times = nrow(obj$model))
 if(any(colnames(obj$model) == "(weights)")) 
  trials <- obj$model[[ncol(obj$model)]]
 # the double bracket (above) gets the index of items within an object
 if (is.factor(y)) 
  y = as.numeric(y) == 2  # Converts 1-2 factor levels to logical 0/1 values
 yhat = obj$fitted.values 
 interval = cut(yhat, quantile(yhat, 0:g/g), include.lowest = TRUE)  # Creates factor with levels 1,2,...,g
 Y1 <- trials*y
 Y0 <- trials - Y1
 Y1hat <- trials*yhat
 Y0hat <- trials - Y1hat
 obs = xtabs(formula = cbind(Y0, Y1) ~ interval)
 expect = xtabs(formula = cbind(Y0hat, Y1hat) ~ interval)
 if (any(expect < 5))
  warning("Some expected counts are less than 5. Use smaller number of groups")
 pear <- (obs - expect)/sqrt(expect)
 chisq = sum(pear^2)
 P = 1 - pchisq(chisq, g - 2)
 # by returning an object of class "htest", the function will perform like the 
 # built-in hypothesis tests
 return(structure(list(
  method = c(paste("Hosmer and Lemeshow goodness-of-fit test with", 
             g, "bins", sep = " ")),
  data.name = deparse(substitute(obj)),
  statistic = c(X2 = chisq),
  parameter = c(df = g-2),
  p.value = P,
  pear.resid = pear,
  expect = expect,
  observed = obs
 ), class = 'htest'))
}

# Osius-Rojek test
# Based on description in Hosmer and Lemeshow (2000) p. 153.
# Assumes data are aggregated into Explanatory Variable Pattern form.

o.r.test = function(obj) {
 # first, check to see if we fed in the right kind of object
 stopifnot(family(obj)$family == "binomial" && family(obj)$link == "logit")
 mf <- obj$model
 trials = rep(1, times = nrow(mf))
 if(any(colnames(mf) == "(weights)")) 
  trials <- mf[[ncol(mf)]]
 prop = mf[[1]]
 # the double bracket (above) gets the index of items within an object
 if (is.factor(prop)) 
  prop = as.numeric(prop) == 2  # Converts 1-2 factor levels to logical 0/1 values
 pi.hat = obj$fitted.values 
 y <- trials*prop
 yhat <- trials*pi.hat
 nu <- yhat*(1-pi.hat)
 pearson <- sum((y - yhat)^2/nu)
 c = (1 - 2*pi.hat)/nu
 exclude <- c(1,which(colnames(mf) == "(weights)"))
 vars <- data.frame(c,mf[,-exclude]) 
 wlr <- lm(formula = c ~ ., weights = nu, data = vars)
 rss <- sum(nu*residuals(wlr)^2 )
 J <- nrow(mf)
 A <- 2*(J - sum(1/trials))
 z <- (pearson - (J - ncol(vars) - 1))/sqrt(A + rss)
 p.value <- 2*(1 - pnorm(abs(z)))
 cat("z = ", z, "with p-value = ", p.value, "\n")
}

# Stukel Test
# Based on description in Hosmer and Lemeshow (2000) p. 155.
# Assumes data are aggregated into Explanatory Variable Pattern form.

stukel.test = function(obj) {
 # first, check to see if we fed in the right kind of object
 stopifnot(family(obj)$family == "binomial" && family(obj)$link == "logit")
 high.prob <- (obj$fitted.values >= 0.5) 
 logit2 <- obj$linear.predictors^2
 z1 = 0.5*logit2*high.prob
 z2 = 0.5*logit2*(1-high.prob)
 mf <- obj$model
 trials = rep(1, times = nrow(mf))
 if(any(colnames(mf) == "(weights)")) 
  trials <- mf[[ncol(mf)]]
 prop = mf[[1]]
 # the double bracket (above) gets the index of items within an object
 if (is.factor(prop)) 
  prop = (as.numeric(prop) == 2)  # Converts 1-2 factor levels to logical 0/1 values
 pi.hat = obj$fitted.values 
 y <- trials*prop
 exclude <- which(colnames(mf) == "(weights)")
 vars <- data.frame(z1, z2, y, mf[,-c(1,exclude)])
 full <- glm(formula = y/trials ~ ., family = binomial(link = logit), 
             weights = trials, data = vars)
 null <- glm(formula = y/trials ~ ., family = binomial(link = logit), 
             weights = trials, data = vars[,-c(1,2)])
 LRT <- anova(null,full)
 p.value <- 1 - pchisq(LRT$Deviance[[2]], LRT$Df[[2]])
 cat("Stukel Test Stat = ", 
     LRT$Deviance[[2]], 
     "with p-value = ", 
     p.value, "\n")
}
```

越写发现东西越多...感觉还是要再看再写一下 **rms**。

# 参考

- [Logistic regression](https://mgimond.github.io/Stats-in-R/Logistic.html)
- [Evaluating the equivalence of different formulations of the scaled Brier score](https://gweissman.github.io/post/evaluating-the-equivalence-of-different-formulations-of-the-scaled-brier-score/)
- [StackExchange: Brier versus AIC](https://stats.stackexchange.com/a/67136)
  
  >Frank Harrell:  
  >AIC is a measure of predictive discrimination whereas the Brier score is a combined measure of discrimination + calibration.

- [FAQ: WHAT ARE PSEUDO R-SQUAREDS?](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/)
- [StackExchange: Which pseudo- R2  measure is the one to report for logistic regression (Cox & Snell or Nagelkerke)?](https://stats.stackexchange.com/q/3559)
- [StackExchange: How to calculate pseudo-R2  from R's logistic regression?](https://stats.stackexchange.com/q/8511)
- [StackExchange: McFadden's Pseudo-$R^2$  Interpretation](https://stats.stackexchange.com/q/82105)
- [StackExchange: Interpreting a logistic regression model with multiple predictors](https://stats.stackexchange.com/q/64788)
- [StackExchange: How to interpret the basics of a logistic regression calibration plot please?](https://stats.stackexchange.com/q/406138)
- [StackExchange: Interpretation of calibration curve](https://stats.stackexchange.com/q/261835)
- [FAQ: HOW DO I INTERPRET ODDS RATIOS IN LOGISTIC REGRESSION?](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/)
- [StackExchange: Evaluating a logistic regression model](https://stats.stackexchange.com/q/71517)
- [StackOverflow: How to evaluate goodness of fit of logistic regression model using residual.lrm in R?](https://stackoverflow.com/q/49264221)
- [StackExchange: Evaluating logistic regression and interpretation of Hosmer-Lemeshow Goodness of Fit](https://stats.stackexchange.com/q/169438)
- [StackExchange: Goodness-of-fit test in Logistic regression; which 'fit' do we want to test?](https://stats.stackexchange.com/q/169000)